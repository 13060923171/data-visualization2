# 数据处理的部分

首先数据处理是采用python语言去处理的，所使用的工具为anaconda，该工具是专门用于数据科学使用的，是为广大数据分析师，数据挖掘师，最火的工具。因为代码众多，无法一一解释每一行代码的含义，不过对于每一块的内容，我都写在对应的代码里面了，可以通过该注释大概明白每一块，代码块所代表的意义是什么，这是总的一个介绍的，如果有什么不齐的地方，到时候你再微信过来问我，在服务范围之内，我看到都会帮你解答的。

共为以下几个步骤：

1. 首先删除重复项

   ![image-20211220230059389](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230059389.png)

2. 然后筛选中文长度大于100的

   ![image-20211220230142197](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230142197.png)

3. 然后把不包含三亚或者海南的文本去除

   ![image-20211220230219776](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230219776.png)

4. 然后再对文中内容进行情感分析，因为paddlehub是百度开源的情感分析库，准确率是目前国内最高的

   所以无需做图片情感分类器训练语料这一块内容

   ![image-20211220230247046](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230247046.png)

5. 具体介绍在这里

   senta_bilstm模型的介绍 
   官方文档:https://www.paddlepaddle.org.cn/hubdetail?name=senta_bilstm&en_category=SentimentAnalysis



# 游客行为规律分析

首先这是效果图

![image-20211220230630170](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230630170.png)

具体做法：

先把路线用txt保存下来，然后把去哪儿和携程的路径保存下来

![image-20211220230749890](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230749890.png)

然后根据总的线路先去划分它们，然后去计算它们的权重

计算权重的方法

![image-20211220230852181](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220230852181.png)

对应的矩阵样式如下：

首先创建一个共现矩阵

![image-20211220231019700](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231019700.png)

然后通过共现矩阵分别获取两两关系及权重，再写入CSV或Excel文件中

![image-20211220231034993](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231034993.png)

最后的样式如下

![image-20211220231102370](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231102370.png)

然后再去统计每一个站点的权重有多少

这里因为数量太多，并没什么意义，所以做了一个筛选，word1-word2权重小于5的全部删除

，然后再去统计剩余每一个站点它的权重，然后去画出对应的图形

计算的权重如下：

![image-20211220231252643](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231252643.png)

最后的图形就是刚刚的那副图形

![image-20211220231319469](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231319469.png)

# 出游动机是怎么划分的

出游动机是首先根据它的内容

然后去判断里面是否存在某个词是符合出游类型的类型

具体方法如下：

![image-20211220231447075](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231447075.png)

然后再根据它的统计的数量去做成一个饼图，统计每个类型的数量及占比

![image-20211220231521926](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231521926.png)

# 关于滞留时间

是根据他们的天数

![image-20211220231624566](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231624566.png)

或者逗留时间啥的，统计

然后它们存在天的，把天这个去掉，只剩数字方便我们统计，然后把它们对应每个人逗留天数做一个统计然后用图表的方式展示

![image-20211220231721081](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231721081.png)

![image-20211220231815142](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231815142.png)



# 关于认知形象

首先是它的词频统计

这里是采用停用词把一些无意义的词去掉，然后再去统计这些词的长度是不是大于2，单个词不算词语，然后统计好之后再把这些词存入csv文件，名为高频词.csv

![image-20211220231952301](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220231952301.png)

![image-20211220232000119](D:/photo/image-20211220232000119.png)

然后我们再根据高频词做成词云图，因为数量太多，所以我们词云只是展示前100个高频词

![image-20211220232059716](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232059716.png)

关于语义网络分析图，其实和上面的是一样的，都是通过词的共现来统计权重，区别只是上面的是针对路线，地方的，而这个是整体的，统计的是全部内容词与与之间的关联，同样也是因为他的词太多了，如果全部统计，只会出现一团黑，没什么意义，所以就统计前100个高频词之间的关联性

![image-20211220232145242](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232145242.png)

# 关于旅游吸引物、旅游交通、旅游住宿、旅游饮食、旅游娱乐、旅游商品6类 描述游客的认知形象

![image-20211220232517222](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232517222.png)

这个它的总的统计，因为数量太多，所以一部分作为参考，选词是从高频词.csv文件这里选取的

并且把相应的内容做成饼图

![image-20211220232641059](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232641059.png)

# 分别画出“旅游吸引物、旅游交通、旅游住宿、旅游饮食、旅游娱乐、旅游商品”6方面排名前5的认知关键词图表

如图所示，该前五主要是从上面的表格选取最高的前5个词，如果数量不够，那么就是去高频词.csv这个文件里面找，最高的词，这样的图有六个，图片太多没必要截，到时候拿到代码查看即可

![image-20211220232750479](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232750479.png)

# 情感形象

![image-20211220232948894](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220232948894.png)

该表格主要从正面情感TOP100高频词这个文件里面，对词进行一个归类，后统计的认知量及认知比例等

并且根据该表格做成一个饼图

![image-20211220233056542](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233056542.png)

 

分别画出“旅游吸引物、旅游交通、旅游住宿、旅游饮食、旅游娱乐、旅游商品”6方面正向情感排名前5（排名最低的5个也要）的认知关键词图表

这样的图一共有12个，正向的6个，反向的也有6个

![image-20211220233136464](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233136464.png)

![image-20211220233150258](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233150258.png)

是根据这两个文件，对相对应的词进行分类，归纳，选择倒数5个和前5个

![image-20211220233225078](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233225078.png)

# 意动形象分析

![image-20211220233328922](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233328922.png)

该表主要结合意动形象的相关词去<正面情感最高的高频词>这个文件里面查找对应词的词频，并且做出对应的统计

这是对应的饼图

![image-20211220233518529](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233518529.png)

# 认知形象、情感形象、意动形象

![image-20211220233547354](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233547354.png)

因为词频数量太多，所以我们对应认知形象去筛选前10个该类型的高频词去统计，去从高频词.csv这个文件去进行筛选的，

关于情感形象是根据《正面情感TOP100高频词》这个文件去进行统计的

关于意动形象是直接采用上面归类好的进行统计

最后这个它的饼图

![image-20211220233757978](https://cdn.jsdelivr.net/gh/13060923171/images@main/img/image-20211220233757978.png)